\section{Reflection}\label{sec:reflection}

In this section, we reflect on the performed work, discuss challenges and opportunities arising from this work, and discuss potential future improvements and research deriving from the OpenDT prototype. 

\subsection{Use cases and requirement assessment}\label{sec:reflection:use-case-requirements}
In this section, we reflect on how our work addresses the use-cases and requirements identified in \Cref{sec:design}.

\begin{enumerate}
[label=\textbf{(UC\arabic*)},leftmargin=0pt,itemindent=3em]
    \item \label{design:uc1} \textbf{Monitoring and operation datacenters}: The current design allows datacenter operators to both monitor and operate massive-scale datacenters. The implemented prototype, functioning as a digital shadow, allows operators to monitor datacenter behaviour, assuming correct linking with a telemetry component, fed with real-world data, with an existing physical twin, and allows operators to conduct what-if analysis in a time and cost efficient way.
    \item \label{design:uc2} \textbf{Researching ICT Infrastructure} The current design and prototype enable stakeholders from the scientific community to experiment with digital twinning ICT infrastructure by building and functional a prototype, also the first and unique digital twinning ecosystem for monitoring and operating ICT infrastructure, aided by LLMs. Our scientific instrument can benefit the scientific community by analyzing how different datacenter configurations would behave under different configurations and under various operational phenomena. Futhermore, OpenDT enables researchers to evaluate the role and abilities of LLMs in operating and SLO-aware adjusting ICT infrastructure.
    \item \label{design:uc3} \textbf{Education} OpenDT can aid students to conduct real-time and continuous what-if analysis on ICT infrastructure under various configurations and running various workload traces. Furthermore, OpenDT can aid as a lab tool in computer systems and digital twinning courses, such as Computer Organization or Distributed Systems, or MOOC courses on edX.
\end{enumerate}

\subsection{Requirement Analysis}\label{sec:design:requirements}
We now assess OpenDT's alignment with the established requirements. We first evaluate whether OpenDT meets the functional requirements.

\begin{enumerate}[label=\textbf{(FR\arabic*)},leftmargin=0pt,itemindent=3em]
    \item \label{design:fr1} \textbf{Digital twin physical ICT infrastructure}: 
    OpenDT receives continuous input from a data broker handled by Apache Kafka, simulates the environment, displays results on a dashboard in real time, thus mimicking a potential real-world ICT infrastructure, and suggests LLM-provided feedback for adjustments such that the datacenter is aligned with SLOs. Albeit essential for a digital twinning ecosystem, the current prototype is not (yet) coupled with a real-world physical datacenter due to the infrastructure and time limitations.
    \item \label{design:fr2} \textbf{Simulate with state-of-the-art scientific instrument}: 
    OpenDT uses OpenDC as a representation model of the system and environment. OpenDC is a peer-reviewed, discrete-event datacenter simulator, community and industry-vetted, widely used in scientific venues and National/European scale projects. Thus, we regard OpenDC as a reliable and most suitable ICT simulator, and couple it with OpenDT as the simulation component, specifically component \circled{J} from~\Cref{fig:opendt-design}.
    \item \label{design:fr3} \textbf{Suggest SLO-aligned changes of the physical twin}: 
    OpenDT suggests LLM-assisted topology adjustments such that the infrastructure under workload meets the practitioner-established SLOs. OpenDT allows the human-in-the-loop to select the topology best aligned with SLOs. The LLM component is present and implemented by the Digital Twin Handler, specifically component~\circled{H} from \Cref{fig:opendt-design}.
    \item \label{design:fr4} \textbf{Autonomous, human-in-the-loop validated}: 
    OpenDT is fully autonomous in monitoring the behavior of the physical twin. The design presented in~\Cref{sec:design} suggests fully autonomous adjustments of the infrastructure, LLM-based, when the adjustments are minor (e.g., reducing the computing power by 1\%), yet require a human-in-the-loop for major decisions (e.g., deciding the priority between two batches of tasks, both of very large-durations, and of various natures). The current prototype of OpenDT requires a human in the loop for approving LLM feedback and contains a flag for making the system fully autonomous; however, the current prototype lacks a decision-based process for distinguishing between minor and major decisions.
\end{enumerate}

We now evaluate OpenDT's adherence to non-functional requirements. However, we note that alignments to NFRs cannot be robustly conducted without robust testing and experimentation. However, according to the course rubrics, evaluation and validation of the performance and fidelity of the engineered prototypes is out of the scope of this report and, thus, skipped for this iteration of the OpenDT research.
\begin{enumerate}[label=\textbf{(NFR\arabic*)},leftmargin=0pt,itemindent=3em]
    \item \label{design:nfr1} \textbf{Rapid, efficient digital twinning}: 
    OpenDT is capable of simulating and receiving LLM feedback on infrastructure adjustments, all in a window 30 seconds between telemetry data. However, while these have been unstructuredly tested, also shown in the course's demo, a robust performance validation is yet to be conducted and envisioned as future work.
    
    \item \label{design:nfr2} \textbf{Accurate adjustment feedback}: 
    OpenDT prototype contains an LLM-based feedback adjustment component which uses the OpenAI's API for GPT 3.5 turbo. We thus conclude that the accuracy of the adjsutment feedback of the OpenDT's ecosystem is directly dependent on the accuracy of the implemented LLM and the structure of the LLM prompt.
    
    \item \label{design:nfr3} \textbf{Massive-scale operation}: 
    OpenDT's design supports massive-scale operation, as detailed in~\Cref{sec:design}. OpenDT's implemented prototype is engineered towards massive-scale operation; firstly, we use Apache Kafka for telemetry and data streaming, a messaging platform that is a state-of-the-art tool and recognized for its good-scalability properties and high throughput; secondly, the adopted simulator is peer-reviewed and community vetted for simulating large-scale workloads, highly accurate (with error rates of under 8\%) and rapidly (OpenDC can simulate months of operation within seconds).
\end{enumerate}



\subsection{Challenges}\label{sec:reflection:challenges}
Throughout the research and engineering process of OpenDT, we encountered various challenges, as expected especially when proposing a first of-its-kind-tool, aimed for massive-scale operation and adhering to industry standards. We divide these challenges in two main categories: challenges encountered during the design process and challenges encountered during the engineering process. Overall, following the methodology proposed and vetted in the community-standard methodology on designing, engineering, and researching distributed (eco)system, we conducted the design and engineering process iteratively and concurrently.

\textit{Design challenges and decisions:} Throughout the design process, we encountered three main challenges. 
1) The high-level design from~\Cref{fig:opendt-design} has been obtained after numerous iterations, on both the design and the engineering side. The main design challenge was determining the role of the machine learning model in predicting infrastructure improvements and the specific role of the human-in-the-loop. We expand on the design choices, considerations, and rationale in~\Cref{sec:design:choices}.
2) Once deciding the role of the machine learning algorithm, we evaluated the main candidates and chose between Reinforcement Learning and Large Language Model based suggestions for infrastructure improvement. After unstructured discussion with experts in computer systems, datacenter operation, and datacenter simulation, and based on these discussions, we concluded that infrastructure adjustment based on a Reinforcement Learning approach is already explored and over-explored, without major benefits to the community. In contrast, LLM is becoming the new state-of-the-art, is yet unexplored, and is becoming of increasingly more interest for the scientific community. We thus decided on implementing the machine learning component following  an LLM-based approach.
3) Cascading from the previous point, an LLM requires robust prompt engineering (although the name, this is still a design choice) to lead to reliable results. After consulting peer-reviewed literature in the field, and after iteratively testing, we adopted the prompt structure proposed in~\Cref{sec:design:llm}.

\textit{Engineering challenges} Similarly, on the engineering process we also encountered challenges, yet of a different nature.
1) Integrating Apache Kafka and ensuring compatibility with OpenDC has been a bottleneck for a few days. While the process itself is not difficult, the implementation, bug fixes, documentation analysis an re-analysis turned out to be more time demanding that initially expected. Yet, it was worth it! Kafka is state-of-the-art and highly scalable.
2) While each component functions well separately, integrating into an orchestrator (i.e., central authority), specifically component \circled{A} from \Cref{fig:opendt-design}, and making all the components tick at the same time, tick correctly, and tick in the correct order represented another main engineering challenge (however, we foresaw this one :D). 


\subsection{Future work}\label{sec:reflection:challenges}
We plan future work for OpenDT towards evolving the current digital twinning to an industry-standard digital twin, used in large-scale research projects and employed by datacenter practitioners in their monitoring and operational processes. Specifically, our plan is four-fold.

Firstly, we plan to link OpenDT with real-world datacenters, which would offer live and real-world telemetry and, in turn, OpenDT would give infrastructure adjustment suggestions, some autononmous, and some approved by a human-in-the-loop.

Then, secondly, we plan to evaluate the performance of OpenDT, the accuracy of OpenDT's LLM component, and how well various LLMs would perform, and, lastly, evaluate the ecosystem against extreme, yet real-world edge cases, evaluate for fault-tolerance, and conduct (more) structured and unstructured interviews and discussions with experts in the field.

Thirdly, we plan to adopt the vetted OpenDT (by this moment, no longer a prototype, but a well-educated, well-behaved, and well-reliable scientific instrument) in large-scale national and international projects run by AtLarge Research and our collaborators. 

Fourthly, yet concurrently with the previous step, we plan on developing educational material around digital twinning ICT infrastructure, aided by OpenDT, and deliver as a series of interactive workshops, seminars, and assignments to educate various academic ages, similarly to previous work from AtLarge Research~\cite{Nicolae2025BSc}. We envision including such workshops as optional material in courses on Computer Organization, Distributed Systems, or in a future edition of the course on Modern Distributed Systems MOOC from edX, which already uses a form of OpenDC and could use an exercise based on OpenDT~\cite{delftx_modern_distributed_systems}.


\subsection{Reflection on the reflection}\label{sec:reflection:reflection}
Concluding the reflection section, and reflecting over the reflection, OpenDT matches the use cases established in \Cref{sec:design}, meets the functional requirements and, at  least superficially, meets the non-functional requirements, established in~\Cref{sec:design}. We encountered challenges, but the design and engineering process have been rewarding. Highly rewarding, especially considering the societal-scale we envision for the future versions of OpenDT. Mainly, we, both as the group from this course and we, AtLarge Research, envision Digital Twins as becoming primary decision-making tools for monitoring and operating datacenters. OpenDT is the first step of our scientific community towards this ambitious, yet achievable goal.