\subsection{Comparison: CoMo-ensemble against B0-B4}\label{sec:experiments:exp3}
% \usepackage{tabularray}

% Paragraph 1 - 100 words
% - Introduce this experiment
% - Throughput and Latency have already been explained so no need to reiterate
% - but why compare CoMo against its components?
% - what might this tell us?
This experiment investigates how CoMo's accuracy compares to that of its individual components. Given that CoMo aggregates the outputs of multiple EfficientNet models, it is essential to evaluate whether this integration leads to meaningful performance improvements. If CoMo’s accuracy is only comparable to or even lower than that of its best-performing component, it would call into question the benefit of this approach. This comparison helps determine whether the increased computational cost of CoMo is justified or if a simpler model selection strategy would be more effective.

\begin{table}[t]
\centering
\caption{CoMo and sub-component inference measurements.}
\label{tab:eval:como-inference}
\begin{tabularx}{\linewidth} {XXXX}
    \toprule
    Model & Throughput (samples/sec) & Latency (ms) & Accuracy  \\
    \midrule
     CoMo  & 321.63                   & 107.159       & 57.80\% \\
b0    & 2748.30                  & 26.008        & 55.31\% \\
b1    & 1370.84                  & 26.419        & 53.70\% \\
b2    & 1182.51                  & 23.878        & 54.63\% \\
b3    & 1057.22                  & 28.331        & 51.41\%     \\
    \bottomrule
\end{tabularx}
\end{table}


% Paragraph 2 - 100 words
% - what are the results?
% - what do they mean? interpretation
% - is the como approach worth it if its accuracy is only the average of its components? 
The results as shown in \Cref{tab:eval:como-inference} demonstrate that CoMo achieves an accuracy of 57.8\%, which is slightly better than the average accuracy of its individual components. Surprisingly, some individual models, such as b0 (55.3\%), come close to CoMo's performance. CoMo suffers from significantly lower throughput (321.6 samples/sec) and higher latency (107.1 ms) compared to its components. These findings raise the question of whether the CoMo approach is justified if its accuracy does not significantly surpass that of its individual models. The added computational cost may not always be worthwhile unless accuracy gains are more substantial.

% Paragraph 3 - 100 words
% perhaps not - HOWEVER
% our como uses a simple mean between its component's predictions
% other functions might be better
% more complex architectures that take better advantage of component predictions
% etc - FUTURE RESEARCH DIRECTIONS
However, CoMo currently uses a simple mean to combine predictions from its components. More sophisticated aggregation methods—such as weighted averaging, confidence-based selection, or ensemble learning techniques—could potentially improve its accuracy beyond the individual models. Additionally, advanced architectures that better leverage component predictions, such as attention mechanisms or decision fusion strategies, might yield better results. Future research should explore these possibilities to determine whether CoMo can truly surpass its components while minimizing the trade-off in performance.
